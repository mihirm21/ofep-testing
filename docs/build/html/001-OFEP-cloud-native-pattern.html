<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>001-OFEP-cloud-native-pattern.md &mdash; OFEP-TESTING 1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="007-OFEP-flag-change-events" href="007-OFEP-flag-change-events.html" />
    <link rel="prev" title="flagd client support driven by OpenFeature Operator" href="014-OFEP-ofo-flagd-client-support.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            OFEP-TESTING
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="016-OFEP-provider-metadata-capability-discovery.html">OFEP-provider-metadata-capability-discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="015-OFEP-provider-client-mapping.html">Provider to client mapping</a></li>
<li class="toctree-l1"><a class="reference internal" href="017-OFEP-single-context-paradigm.html">OFEP-single-context-paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="014-OFEP-ofo-flagd-client-support.html">flagd client support driven by OpenFeature Operator</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">001-OFEP-cloud-native-pattern.md</a></li>
<li class="toctree-l1"><a class="reference internal" href="007-OFEP-flag-change-events.html">007-OFEP-flag-change-events</a></li>
<li class="toctree-l1"><a class="reference internal" href="004-OFEP-kubernetes-sync-service.html">004-OFEP-inotfiy-interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="003-OFEP-CUE-upstream.html">003-OFEP-CUE-upstream</a></li>
<li class="toctree-l1"><a class="reference internal" href="009-OFEP-add-dispose.html">Add dispose functionality to API</a></li>
<li class="toctree-l1"><a class="reference internal" href="012-OFEP-inline-evaluation.html">Inline Evaluation of Flag Rules</a></li>
<li class="toctree-l1"><a class="reference internal" href="006-OFEP-flagd-sockets.html">NAME</a></li>
<li class="toctree-l1"><a class="reference internal" href="011-OFEP-transaction-context-propagation.html">Transaction Context Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="005-OFEP-provider-hook.html">005-OFEP-provider-hook.md</a></li>
<li class="toctree-l1"><a class="reference internal" href="000-OFEP-template.html">NAME</a></li>
<li class="toctree-l1"><a class="reference internal" href="002-OFEP-kubecon-demo.html">002-OFEP-kubecon-demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="013-OFEP-ofo-flag-service.html">flag service deployment driven by OpenFeature Operator</a></li>
<li class="toctree-l1"><a class="reference internal" href="008-OFEP-provider-flag-metadata.html">OFEP-007: Surfacing flag metadata</a></li>
<li class="toctree-l1"><a class="reference internal" href="OFEP_Index.html">OFEP Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="010-OFEP-flagd-grpc-sync.html">OFEP: Add gRPC sync support to flagd</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OFEP-TESTING</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="ofep_docs.html">&lt;no title&gt;</a></li>
      <li class="breadcrumb-item active">001-OFEP-cloud-native-pattern.md</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/001-OFEP-cloud-native-pattern.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ofep-cloud-native-pattern-md">
<h1>001-OFEP-cloud-native-pattern.md<a class="headerlink" href="#ofep-cloud-native-pattern-md" title="Permalink to this heading"></a></h1>
<section id="state-approved">
<h2>State: APPROVED<a class="headerlink" href="#state-approved" title="Permalink to this heading"></a></h2>
<p>Hello folks,</p>
<p>I wanted to share some thoughts on an initial architectural design for the open feature project from the Kubernetes layer.
From my initial engagement and involvement with the group, this will be primarily focused on the server-side capability of presenting feature flags to container workloads.</p>
</section>
<section id="assumptions">
<h2>Assumptions<a class="headerlink" href="#assumptions" title="Permalink to this heading"></a></h2>
<p>We initially assume that workloads will be some sort of web server, however, I would like to incorporate into the design the support of local AF_UNIX sockets for processes to manage their control flow based on external flags. To that end, we are also basing much of our overarching narrative on the ability to perform some sort of A/B testing; at this point not considering the use of flags to manage logic based on some sort of event activity - horizontal pod autoscaling as an example.</p>
<p>In my following example and illustrations, I have created the latter example of a flask based web server that is presented on the public internet. The flag system however is server-side and should not be programmable from the world wide web. At this time to me, it seems illogical to need to worry about RBAC/ACL and TLS concerns when making a highly sensitive API like this available to the public.</p>
</section>
<section id="operator-pattern">
<h2>Operator pattern<a class="headerlink" href="#operator-pattern" title="Permalink to this heading"></a></h2>
<p>The typical Operator pattern in this context is appropriate over a stand-alone web service for the previously mentioned reasons but also because of the stateless and scalable nature of the design. For example; a multi-tenant environment is constrained by namespacing and service accounts; something which we would have to overcome if writing a centralised cluster-wide API.</p>
<p>In addition to this, there is a “feel” factor in using this pattern as it is easy to design, manage and augment.
I suggest that in conjunction with reconciliation on a primary custom resource, there is also the use of a mutating and validating admission webhook to enable key functionality.</p>
</section>
<section id="workflow">
<h2>Workflow<a class="headerlink" href="#workflow" title="Permalink to this heading"></a></h2>
<p>In a nutshell, there are two types of a control flow for setting a feature flag.
Direct set and standing orders are the pet names for them in this illustration.</p>
<p>These combined should cover the majority of use cases and get the project into a rapidly usable state given they are fairly well-trodden patterns for interacting with services.</p>
<!-- <img src="images/001-01.png" width="300"> -->
<p><img alt="unlabelled_image" src="_images/001-01.png" /></p>
</section>
<section id="direct-set">
<h2>Direct set<a class="headerlink" href="#direct-set" title="Permalink to this heading"></a></h2>
<p>This pattern uses labels/annotations ( I am undecided currently as there are penalties on the size of the YAML file for storing large histories here ) directly for the open feature labelling system or a reference to an object that does; for example:</p>
<p>openfeature.io/standingorder: custom-resource-1
The key point here is that the deployment encapsulates where it wants to derive its feature flags from - this makes the issue of the owner referencing and mapping the configuration to the agent trivial.</p>
<p>Once a deployment has been configured with the appropriate annotations/labels then a cluster with OpenFeature Operator running will employ an optional namespace scoped set of webhooks.</p>
<p>validating admission webhook
The purpose of this webhook is to validate any inline JSON that has been configured with a manifest and to provide any additional context that needs to be encoded. This might well be appropriate in a multi-tenant environment to write remarks from an authoritative source.</p>
<p>For example:</p>
<p>openfeature.io/operator-remarks: namespaced, scoped, refreshable
mutating admission webhook
The job of this webhook is to run after the validating admission component and inject the OpenFeature agent into the configuration object and complete the required setup to present it to the host container ( the container running the desired workload for feature flagging ) within the pod.</p>
<p>This webhook will deal with configuration such as open port, transport type and configuration path locations ( possibly expanding to backing type such as PVC vs configmap ).</p>
<section id="configuration-reloading">
<h3>Configuration reloading<a class="headerlink" href="#configuration-reloading" title="Permalink to this heading"></a></h3>
<!-- <img src="images/001-02.png" width="300"> -->
<p><img alt="unlabelled_image" src="_images/001-02.png" /></p>
<p>In the scenario of a feature flag being altered, the configuration would be modified directly by the controller-manager and the agent would micro reload to present to the host container ( perhaps using the confd workflow ).</p>
</section>
</section>
<section id="standing-orders">
<h2>Standing orders<a class="headerlink" href="#standing-orders" title="Permalink to this heading"></a></h2>
<p>This flow is supplementary to writing annotation directly to the deployment and can coexist within the same ecosystem.
The idea here is that you have a custom resource that can be programmable but might not necessarily be immediately associated with an application. It would be possible for an OpenFeature agent to fetch from a standing order custom resource rather than it’s locally scoped configmap in this scenario.</p>
<p>This is important as it gives a known and persistent custom resource for programming feature flag states but also encourages a subscribe mechanic from a deployment. It might look like the following:</p>
<p>openfeature.agent/standing-orders-resource: custom-resource-one”
openfeature.agent/standing-orders-resource-namespace: default”
An argument against an API server
I believe there was an initial idea to create a cluster-wide API server, which I would discourage.
The problems presented with RBAC/ACL/TLS and other features are not-intractable but they are secondary to wider architectural design issues. I have laid out a few here.</p>
</section>
<section id="high-scale-stateful-configuration-management">
<h2>High-scale stateful configuration management<a class="headerlink" href="#high-scale-stateful-configuration-management" title="Permalink to this heading"></a></h2>
<p>Because having state kept in memory is just a bad idea, especially with many engineers attempting to program against the backend API for OpenFeature, my thinking is we would persist this into state files.</p>
<p>In a large cluster with a centralised server, the thinking is that the configuration state files would need to be persisted to disk, this isn’t alone a problem but a single file would create a complex nested object construct which would scale inversely to the number of workloads using open feature flags. This could be compensated by distributing to a state file per workload but at the expense of complexity. Managing orphaned files and alternative formats then compound this issue.</p>
</section>
<section id="security">
<h2>Security<a class="headerlink" href="#security" title="Permalink to this heading"></a></h2>
<p>All workloads requiring access to a centralised server will need both access to the kubernetes control plane, the API server and the host overlay network. There are also risks with turning off someone else’s feature flags as discussed which means a lot of machinery around security needs to be built and managed here - how do we check service accounts are valid? How do we check the authority level? How do we map a service account to feature flag permissions?</p>
<p>As you can see this design is an invitation to reinvent the wheel.</p>
</section>
<section id="performance">
<h2>Performance<a class="headerlink" href="#performance" title="Permalink to this heading"></a></h2>
<p>Network calls will increase as workloads increase.
Neither design ( operator vs api ) are immune to this, however, the distance of calls will be increasing across nodes on the host overlay network unless there is a separate tenant network for calls to the OpenFeature API server.</p>
<p>In addition, when the API server fails or restarts all calls will start timing out to it unless there is behaviour introduced into the agents ( which is completely possible ). However, the remark about a single point of failure holds true.</p>
<!-- <img src="images/001-03.png" width="300"> -->
<p><img alt="unlabelled_image" src="_images/001-03.png" /></p>
<!-- ![OFO client architecture](images/001-03.png "OFO Client Architecture"){: width="300"} -->
<!-- ![](images/001-03.png){: width="300"} -->
<p>Let me know your thoughts</p>
</section>
<section id="additional-architecture">
<h2>Additional architecture<a class="headerlink" href="#additional-architecture" title="Permalink to this heading"></a></h2>
<!-- <img src="images/001-04.png" width="300">  -->
<p><img alt="unlabelled_image" src="_images/001-04.png" /></p>
</section>
<section id="post-kubecon-configuration">
<h2>Post Kubecon configuration<a class="headerlink" href="#post-kubecon-configuration" title="Permalink to this heading"></a></h2>
<p>We had a meet up at Kubecon that touched on a few key issues that have helped to improve and inform this design pattern.</p>
<section id="remote-endpoint-configuration">
<h3>remote endpoint configuration<a class="headerlink" href="#remote-endpoint-configuration" title="Permalink to this heading"></a></h3>
<p>Given that we want to accommodate vendors and enable them within this ecosystem, we are going to introduce a concept that allows for the Flag Custom Resource to indicate the desire for a remote endpoint point. To that end, it will enable a completely new set of capabilities from the host vendor to interact at the pod level with processes for the cloud-native provider. It serves as a mechanism to instigate a remote fetch capability that would merge or override the local configuration within the custom resource.</p>
<p>It could possibly have some of these types of fields:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">remoteFlagProvider</span><span class="p">:</span>
  <span class="nb">type</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">implementation</span> <span class="n">name</span><span class="o">&gt;</span> 
  <span class="n">strategy</span><span class="p">:</span> <span class="n">merge</span>
  <span class="n">credentials</span><span class="p">:</span>
   <span class="n">secret</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">secret</span> <span class="n">name</span><span class="o">&gt;</span> 
<span class="n">Agent</span>
</pre></div>
</div>
</section>
<section id="integration-points">
<h3>Integration points<a class="headerlink" href="#integration-points" title="Permalink to this heading"></a></h3>
<p>In order to enable host containers to consume the sidecar then there should be multiple protocols to do so.
There was an initial proposal to incorporate the AF_LOCAL/AF_UNIX socket family and within that family, we should decide whether is a need to support SOCK_STREAM and SOCK_DGRAM, I would initially suggest only supporting SOCK_STREAM.
This would enable us to further layer HTTP protocol support on top where required.</p>
<!-- <img src="images/001-05.png" width="300"> -->
<p><img alt="unlabelled_image" src="_images/001-05.png" /></p>
</section>
</section>
<section id="flow">
<h2>Flow<a class="headerlink" href="#flow" title="Permalink to this heading"></a></h2>
<p>The below illustration has been updated also to reflect the current thinking around the initialisation flow of the flagging system.</p>
<p>That said there are some learnings from Istio and concerns around side car overhead - namely around upgrading and maintenance. As such it is worth exploring a pattern for rolling or upgrading sidecars, as the implication is that this will force a deployment rollout due to the change on the deployment object ( and other resource types sts/ds)</p>
<!-- <img src="images/001-06.png" width="300">   -->
<p><img alt="unlabelled_image" src="_images/001-06.png" /></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="014-OFEP-ofo-flagd-client-support.html" class="btn btn-neutral float-left" title="flagd client support driven by OpenFeature Operator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="007-OFEP-flag-change-events.html" class="btn btn-neutral float-right" title="007-OFEP-flag-change-events" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Mihir Mittal.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>